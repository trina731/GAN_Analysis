# Generative Adversarial Network
Implementation of a Generative Adversarial Network (GAN) for the purpose of digit generation, clothing article generation, and generation of human faces, using the `MNIST`, `FashionMNIST`, and `CelebFaces` datasets. The original paper can be found [here](https://arxiv.org/pdf/1406.2661.pdf).

## Theory

In a GAN, there are two models which train each other through a minimax game – a generative model tries to create realistic data instances and a discriminative model classifies data as real or generated by the generative model. The generator is trained to fool the discriminator by making the generated data close to the original data distribution while the discriminator is trained to correctly differentiate between the generator’s output and the original data. 

## Datasets

The `MNIST` dataset consists of 70k (60k train, 10k test) handwritten images of the digits 0 − 9. The `FashionMNIST` dataset is a dataset of 70k (60k train, 10k test)
images of articles of clothing taken from Zalando, an European fashion website. The `CelebFaces` dataset is a large-scale, unlabeled face attributes dataset with over 200,000 celebrity images. We split the train data into batches of size 64.

## Models

The following 3 model architectures are implemented:
1. (`Vanilla-GAN-Generate-MNIST.ipynb`) Consists of a generator & discriminator implemented with feed-forward layers. This was used for digit generation using the `MNIST` and `FashionMNIST` datasets. 
2. **Experiment 1: (`CNNs.ipynb`)** GAN using convolutional layers, and tested on all 3 datasets mentioned above. 
3. **Experiment 2: (`Wasserstein-GAN-Generate-MNIST-ipynb`)** Variant GAN known as a Wasserstein GAN (outlined in [here](https://agustinus.kristia.de/techblog/2017/02/04/wasserstein-gan/)) was implemented, and its performance was compared to the original GAN model. 
